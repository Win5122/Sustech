数字化记忆灾害  Report  
人员分工  
赵伟栋： 数据收集整理，剪辑视频  
陶文晖： 后端代码编写，情绪分析，制作后端组视频  
刘天恩： 数据收集整理  
邱天润： 前端数据展示部分框架搭建，部分图表制作  
郑青禾： 前端地图部分展示制作  
李玉金：前端部分首页制作  
项目流程  
(1)数据爬取  
(2)清洗数据并做成能导入数据库的表格  
(3)统计分析数据、数据可视化  
代码组成  
后端部分  
收集数据： 使用 selenium 模拟用户使用浏览器的过程，使用 etree解析 html结构，获取用户
id，性别，帖子内容，点赞评论转发，粉丝数，地址等。  
情绪分析：  使用 hanlp语言模型，人工标签的方式进行训练，进行基本的正面，负面，中性
的情绪识别。  
整理数据： 将数据整理成为 CSV数据集，便于前端分析调用。  
前端部分  
总述  
我们的前端部分使用 Vue和T-Design搭建，分为首页概览和各个具体分析功能两个部分，主
要实现了以下界面和功能，来更好地交互式展示和分析我们所获取到的数据。  
Home（主页部分）  App.vue  主页和总框架  
Map（地图部分）  MapView.vue  地图面板  mainMap.vue  地图组件  
Analytics （分析部分）  Analytics.vue  分析部分界面  
data.js  处理数据  
histogram.js  柱状图组件  
piechart.js  饼图组件  
word -cloud.js  词云组件  
AI Chat（大模型部分）  AI.vue  大模型交互界面  
claude.js  与大模型（ Claude）交互  
主页部分详述  
在主页中， 根据现有数据文件分析数据并可视化了热度趋势，集聚效应，讨论度，访问渠道和
热点排行 等具体数据，借助数据大屏的形式实现直观可视化。  
分析部分详述  
在这一部分中，我们使用  d3 的类库，通过代码实现了柱状图、饼图、词云的效果。同时，我
们给出了一个控制套件，可以选择关键词、分析的内容，并支持选择对指定时间范围进行分
析。数据来源为请求获取的 CSV格式数据文件。  
对于具体的内容，我们以基于人工智能模型的分词工具  jieba 为基础进行中文分词，增加了可
以分析的内容丰富程度。  
地图部分详述  
引入  echart 中国地图包，使用热力图模式， 便于展示数据在地区之间的差异。解析后端整理
的csv文件，提取出 时间、地点、类型等信息，并在前端可视化。  
关键点和功能包括：  
日期范围选择器 ： 使用了第三方的日期范围选择器，允许用户选择特定的时间范围进行数据
可视化。  
关键词选择下拉菜单 ： 提供了一个下拉菜单，用户可以从预定义的关键词列表（ tagsList）中
选择关键词。  
地图容器 ： 使用 ECharts库初始化地图容器，展示中国地图，并提供交互功能。地图上的各个
省份具有数据点，数据点的值决定了该省份的颜色深浅。  
异步数据获取 ： 通过异步请求获取 CSV格式的数据文件，解析数据后更新地图图表，反映出
选定关键词和日期范围内的信 息量分布。  AI 大模型部分详述  
在这一项目中，我们还使用了 Claude大模型来对我们所获取的信息进行分析。  
我们接入了 Claude API ，并构建了一个问答界面，通过流式输入输出确保良好的用户体验。由
于token window 所限，我们暂时支持的是对某一个特定主题进行分析（这也是选择接入
Claude模型而非 GPT的原因，因为 GPT所能提供的 token window 更小） ；不过从后续效果展
示截图所见，我们事实上也得到了令人满意的结果，并支持多轮问询。  
数据部分详述  
收集要求  
1.关键词：  
三组关键词之间的关系是 A并B并C。 
主题：  上海疫情  
时间段： 2022.3.1 -2022.6.30  
A组 新冠 |新型冠状病毒 |疫情 |上海市疫情防控 |上海疫情 |上海市新冠疫情防  
B组 防控政策 |管理措施 |联防联控机制综合组 |治疗指南 |实时动态 |地图 |感染情况 |
故事 |讲述 |口述 |日记 |知识 |建议 |解答 |辟谣 |专家 |医生 |中医 |求助 |互助 |热线 |救援
|拼团 |外卖 |快递 |事迹 |纪实 |宣布  
C组 团长 |封校 |可乐 |咖啡 |硬通货 |刘耕宏 |健身 |合围区 |移民 |外国人 |外籍人士 |辟谣 |
压茬 |历史无阳 |研判 |无差别 |保供 |哄抬物价 |必需品 |小区 |楼组长 |全力以复 |点
式复工 |有序解封 |有序放开 |有限流动 |关门不歇业 |解封不解防 |自治 |隔离 |核酸 |
居家 |网课 |网购 |出境 |入境 |团购 |封城 |封控 |解封 |出入通行证 |口罩 |防护服 |连花
清瘟 |酒精 |武汉病毒 |SARS|非典 |李文亮 |方方日记 |世界卫生组织 |WHO|疾控
|CDC|卫健委 |方舱 |火神山 |雷神山 |新闻发布会 |驰援 |志愿者 |病例 |密接 |传染链 |
群体免疫 |清零 |静默 |非必要不 |健康码 |场所码 |绿码 |行程码 |消杀 |复工复产 |应
收尽收 |应检尽检 |大白 |流调 |疫苗 |时空伴随 |转运 |网格 |抢菜 |囤物资 |张文宏 |钟
南山 |熔断 |后遗症 |白肺 |呼吸机 |ECMO|肺部纤维化 |健康宝 |毒王 |超级传播者 |
闭环 |拭子 |混检 |单人单检 |三天三检 |落地检 |风险地区 |恶意反乡 |偷渡 |管控 |气
溶胶 |人传人 |无害化处理 |无症状 |港口 |医学观察 |境外输入 |抑郁 |焦虑 |恐慌 |未知|疲惫 |医疗资源挤兑 |ICU|PCR| 重症 |变异 |毒株 |旅游 |娱乐 |餐饮 |可防可控 |抗
疫|躺平 |物价 |星号 |自我防护 |勤洗手|污名化 |假新闻 |种族歧视 |报复性消费 |周
边游 |防疫指挥小组 |科学防疫 |群防群控 |无接触配送 |滞留 |共存 |居委会 |孕妇 |女
性|婴幼儿 |青少年 |青年 |中年 |老年 |病患 |慢性病 |残障 |残疾  
排除
词 判决书  股份有限公司  控股有限公司  人才引进资格  道指跌  纳指跌  标普
500跌 中概股普跌  资源股  加密货币  国防  汽车之家  
 
2.数据抓取所需字段：  
1)序号   
2)标题 /微博内容   
3)原文链接  （原文附带的链接）  
4)日期   
5)来自（微博客户端 /移动端 /网页版 .....） 
6)媒体类型   
7)原文作者   
8)认证类型（政府 /企业团体 /个人认证 /普通用
户）  
9)粉丝数  
10)原文   11)原文内的标签   
12)原文内容的情绪（如果很复杂可提前
告知）  
13)信源地域   
14)精准地域   
15)原创 /转发   
16)涉及词（抓取方案中涉及的词标亮）  
17)转发数   
18)评论数   
19)点赞数   
20)图片 /视频 /.... 
  效果展示  
 
部分搜集数据  
 
部分收集数据， None表示是否进行高级搜索  
 
首页概览界面  
 
 
分析页面  
 
大模型问答页面  
 
 
  
 
选择关键词  鼠标移到地图上显示具体数值  
 
项目总结  
在数字化记忆灾害项目中，我们团队充分发挥了各自专业领域的能力。通过使用 Selenium
进行数据采集和 etree进行 HTML结构解析，我们成功获取了用户信息和帖子内容，并利用
hanlp语言模型实现了情感分析。在前端开发方面， Vue和T-Design的应用使得我们能够以直
观而交互式的方式展示数据，同时利用 d3和ECharts等库创造了多种图表效果。引入 Claude
大模型为项目增加了深度，通过 Claude API 进行问答分析，我们成功探索了特定主题的细节。
这次经验让我们深刻认识到了团队协作和数据处 理在项目中的关键作用，同时为我们提供了宝
贵的学习机会，为未来的数据分析和项目开发打下了坚实基础。  